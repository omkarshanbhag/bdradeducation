{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import shutil\n",
    "import os \n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import copy\n",
    "from torchvision import transforms, utils, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load info csv's \n",
    "train_info = pd.read_csv('./mass_case_description_train_set.csv')\n",
    "test_info = pd.read_csv('./mass_case_description_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#open training image directory\n",
    "train_str = \"./ImageData/CBIS-DDSM_TRAIN\"\n",
    "train_dir = os.fsencode(train_str)\n",
    "\n",
    "#open testing image directory\n",
    "test_str = \"./ImageData/CBIS-DDSM_TESTING\"\n",
    "test_dir = os.fsencode(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All Preprocessing steps involved from the first part of the project \n",
    "def load_image(filepath, height, width):\n",
    "    img = pydicom.dcmread(filepath, force=True)\n",
    "    try:\n",
    "        img = img.pixel_array\n",
    "    except:\n",
    "        return((0,0))\n",
    "    img = cv2.resize(img, (height, width))\n",
    "    pattern_id = re.compile(r'P\\_\\d\\d\\d\\d\\d')\n",
    "    match_id = re.search(pattern_id, filepath)\n",
    "    breast_density = - 1 \n",
    "    breast_density = [get_density(filepath, match_id)]\n",
    "    return((img, breast_density))            \n",
    "\n",
    "#Pairs the image with density value \n",
    "def get_density(filepath, match_id):\n",
    "    patient_id = filepath[match_id.span()[0]:match_id.span()[1]]\n",
    "    pattern_train = re.compile(r'Training')\n",
    "    match_train = re.search(pattern_train, filepath)\n",
    "    if match_train:\n",
    "        des_file = train_info\n",
    "    else:\n",
    "        des_file = test_info\n",
    "    density_val = des_file.loc[des_file['patient_id'] == patient_id, 'breast_density']\n",
    "    density_val = density_val.iloc[0]\n",
    "    return(density_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for loading data given directory\n",
    "def load_data(directory):\n",
    "    X = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if count != 0 and count % 3 == 0:\n",
    "            for file in files:\n",
    "                p=os.path.join(root,file)\n",
    "                abs_filepath = os.path.abspath(p)\n",
    "                loaded_img = load_image(str(abs_filepath)[2:-1], 299, 299)\n",
    "                X.append(loaded_img[0])\n",
    "                y.append(loaded_img[1])\n",
    "        count += 1\n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading training and testing data \n",
    "X_train, y_train = load_data(train_dir)\n",
    "X_test, y_test = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing to remove failed loads\n",
    "def reformat_data(X, y):\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "    for i in range(len(X)):\n",
    "        if type(X[i]) != int:\n",
    "            temp_X.append(X[i])\n",
    "            temp_y.append(y[i][0])  \n",
    "\n",
    "    #turning y into binary values \n",
    "    temp_y = [0 if i < 2 else 1 for i in temp_y]\n",
    "    return(temp_X, temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reformat the data \n",
    "X_train, y_train = reformat_data(X_train, y_train)\n",
    "X_test, y_test = reformat_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loaded = np.load(\"img_training_data.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define number of output classes \n",
    "output_classes = 2\n",
    "\n",
    "#Define the Learning rate \n",
    "learning_rate = 0.03\n",
    "\n",
    "#Create model with output_classes number of nodes on the last layer\n",
    "resnet18 = models.resnet18(num_classes=output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "def preprocess_image(image):\n",
    "    data_copy = copy.deepcopy(image)\n",
    "    data_copy = np.asarray(data_copy)\n",
    "    data_copy = data_copy.astype(dtype = 'float32')\n",
    "    final_list = [data_copy, data_copy, data_copy]\n",
    "    final_list = np.asarray(final_list)\n",
    "    return(final_list)\n",
    "\n",
    "\n",
    "def make_torch_dataset(numpy_images, numpy_labels):\n",
    "    torch_images = [torch.from_numpy(preprocess_image(x)).float() for x in numpy_images]\n",
    "    # TODO: figure out what the datatype of the labels should be\n",
    "    torch_labels = torch.from_numpy(numpy_labels).long()\n",
    "    return torch_images, torch_labels\n",
    "\n",
    "\n",
    "class ImageDataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, numpy_images, numpy_labels):\n",
    "        'Initialization'\n",
    "        torch_images, torch_labels = make_torch_dataset(numpy_images, numpy_labels)\n",
    "        self.images = torch_images\n",
    "        self.labels = torch_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "\n",
    "        return self.images[index], self.labels[index]\n",
    "    \n",
    "torch_train_dataset = ImageDataset(X_train, y_train)\n",
    "torch_test_dataset = ImageDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 8\n",
    "shuffle = True\n",
    "\n",
    "train_dataloader = data.DataLoader(torch_train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dataloader = data.DataLoader(torch_train_dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (inp, target) in enumerate(train_loader):\n",
    "\n",
    "        # compute output\n",
    "        output = model(inp)\n",
    "        loss = criterion(output, target) # will barf if the label datatype is wrong\n",
    "        print(\"Loss: \", loss)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # train for one epoch\n",
    "    train(train_dataloader, resnet18, criterion, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 76.28865979381443 %\n"
     ]
    }
   ],
   "source": [
    "resnet18.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = resnet18(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation and Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "final_labels = []\n",
    "\n",
    "for images, labels in test_dataloader:\n",
    "    outputs = resnet18(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    final_predictions.append(predicted.numpy())\n",
    "    final_labels.append(labels.numpy())\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for val in final_predictions:\n",
    "    for v in val:\n",
    "        preds.append(v)\n",
    "        \n",
    "for val in final_labels:\n",
    "    for v in val:\n",
    "        labels.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  46],\n",
       "       [  0, 148]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confusion matrix depicts the number of true negatives (top, left), false negatives (bottom, left), true positives (bottom, right) and false positives (top, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.        , 0.17391304, 1.        ]), array([0.        , 0.87162162, 1.        ]), array([2, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "sklearn.metrics.roc_curve(labels, preds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
